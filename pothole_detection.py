# -*- coding: utf-8 -*-
"""pothole detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zav-p71HGFFuE7qSXpcS-A0RQio_JlJU

# **Connecting with drive**
"""

from google.colab import drive
drive.mount("/content/gdrive")
# tf.keras.backend.clear_session()

"""# **Part 1: Using YOLOv5**

## **Install Yolov5**
"""

# Commented out IPython magic to ensure Python compatibility.
# YOLOV5
!git clone https://github.com/ultralytics/yolov5  # clone repo
!pip install -U -r yolov5/requirements.txt  # install dependencies
# %cd /content/yolov5
# ******************************************************************************
!pip install -r requirements.txt  # install dependencies
# %cd yolov5
# ******************************************************************************
import torch
from IPython.display import Image  # for displaying images
#from utils.google_utils import gdrive_download  # for downloading models/datasets

print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
# ******************************************************************************

"""##**Custom Dataset and detection using YOLOV5**"""

# Commented out IPython magic to ensure Python compatibility.
# Download Custom Dataset
# %mkdir /content/my_dataset/
# %cd /content/my_dataset
!curl -L "https://public.roboflow.com/ds/NEbdAjTGUx?key=kiNIE1s0A0" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip

# new torch for using GPU
!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html

# Commented out IPython magic to ensure Python compatibility.
# # Train Yolov5 on Custom Dataset
# %%time
# %cd /content/yolov5/
# !python train.py --img 416 --batch 16 --epochs 300 --data /content/my_dataset/data.yaml --cfg /content/yolov5/models/hub/pothole_model.yaml --weights yolov5l.pt --name pothole_model_results --cache
#

# Commented out IPython magic to ensure Python compatibility.
# Export Saved YOLOv5 Weights for Future Inference
"""
from google.colab import drive
drive.mount("/content/gdrive")
"""
# %cp /content/yolov5/runs/train/pothole_model_results/weights/best.pt  /content/gdrive/MyDrive

print("Done ...")

# Commented out IPython magic to ensure Python compatibility.
# Evaluate Custom YOLOV5 Detector Performance
# %load_ext tensorboard
# %tensorboard --logdir runs

# we can also output some older school graphs if the tensor board isn't working for whatever reason... 
from IPython.display import Image
Image(filename="/content/yolov5/runs/train/pothole_model_results/results.png", width=1000)  # view results.png

# display our ground truth data
Image(filename="/content/yolov5/runs/train/pothole_model_results/train_batch2.jpg", width=900)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolov5/
!python val.py --weights /content/yolov5/runs/train/pothole_model_results/weights/best.pt --data /content/my_dataset/data.yaml --name my_yolo_model

# Display Val images
import glob
from IPython.display import Image, display

for imageName in glob.glob("/content/yolov5/runs/val/my_yolo_model/*.*"): 
    display(Image(filename=imageName))
    print("\n")

# Commented out IPython magic to ensure Python compatibility.
# Inference 1 image :
# %cd /content/yolov5/
!python detect.py --weights /content/yolov5/runs/train/pothole_model_results/weights/best.pt --img 416 --conf 0.5 --source /content/my_dataset/test/images/img-105_jpg.rf.3fe9dff3d1631e79ecb480ff403bcb86.jpg

# display 1 image :
from IPython.display import Image, clear_output  # to display images
Image(filename="/content/yolov5/runs/detect/exp/img-105_jpg.rf.3fe9dff3d1631e79ecb480ff403bcb86.jpg", width=600)

# Commented out IPython magic to ensure Python compatibility.
# Inference all images :
# %cd /content/yolov5/
!python detect.py --weights /content/yolov5/runs/train/pothole_model_results/weights/best.pt --img 416 --conf 0.5 --source /content/my_dataset/test/images

# Display inference on ALL test images
import glob
from IPython.display import Image, display

for imageName in glob.glob("/content/yolov5/runs/detect/exp3/*.jpg"): #assuming JPG
    display(Image(filename=imageName))
    print("\n")

"""## **Saved Model**"""

# # Inference video by saved model:
# %cd /content/yolov5/
# !python detect.py --weights /content/gdrive/MyDrive/best.pt  --conf 0.4 --source /content/MyDrive/IMG_4844.MOV

# # Save the result on drive
# %cp /content/yolov5/runs/detect/exp2/IMG_4844.MOV  /content/gdrive/MyDrive

# Commented out IPython magic to ensure Python compatibility.
# Inference all images by saved model:
# %cd /content/yolov5/
!python detect.py --weights /content/gdrive/MyDrive/best.pt --img 416 --conf 0.4 --source /content/my_dataset/test/images

# display inference on ALL test images
import glob
from IPython.display import Image, display

for imageName in glob.glob("/content/yolov5/runs/detect/exp5/*.jpg"): #assuming JPG
    display(Image(filename=imageName))
    print("\n")

"""## **Inference** """

# Python program to explain os.system() method 
      
# M1
"""
import os 
cmd = "python detect.py --weights /content/gdrive/MyDrive/best.pt --img 416 --conf 0.4 --source /content/my_dataset/test/images"   
os.system(cmd)
"""
# M2
"""
import subprocess
cmd = "python detect.py --weights /content/gdrive/MyDrive/best.pt --img 416 --conf 0.4 --source /content/my_dataset/test/images"
failure = subprocess.call(cmd, shell=True)
try:
    output = subprocess.check_output(cmd, shell=True,
                                     stderr=subprocess.STDOUT)
except subprocess.CalledProcessError:
    print('Execution of "%s" failed!\n' % cmd)
    sys.exit(1)

# Process output
for line in output.splitlines():
  print(line)
"""
# M3
import subprocess as sp
cmd = "python detect.py --save-txt --weights /content/gdrive/MyDrive/best.pt --img 416 --conf 0.4 --source /content/my_dataset/test/images/img-146_jpg.rf.61be25b3053a51f622a244980545df2b.jpg"

output = sp.getoutput(cmd)
print (output)

l = len(output.split("\n"))
print (l)
path_result = output.split("\n")[l-3]

print (path_result)
path_img = path_result.split("to ")[1]
path_img = path_img.encode()
path_img = str(path_img).split("/")[2].split("\\")[0]
print(path_img)
path_img = "/content/yolov5/runs/detect/"+path_img+"/img-146_jpg.rf.61be25b3053a51f622a244980545df2b.jpg"
print(path_img)

import torch
from IPython.display import Image, clear_output  # to display images
Image(filename=path_img, width=600)

!pip install --upgrade gradio

# https://www.gradio.app/ml_examples

# Using saved model
import gradio as gr
import requests
import cv2
import subprocess as sp
from PIL import Image

print(gr.__version__)
def inference(img):
  my_image = img.name
  cmd = "python /content/yolov5/detect.py --save-txt --weights /content/gdrive/MyDrive/best.pt  --conf 0.5 --source "+my_image
  output = sp.getoutput(cmd)
  l = len(output.split("\n"))
  path_result = output.split("\n")[l-3]
  path_img = path_result.split("to ")[1]
  path_img = path_img.encode()
  path_img = str(path_img).split("/")[2].split("\\")[0]
  file_name = "runs/detect/"+path_img+"/"+my_image.split("/")[2]
  img_result = Image.open(file_name)
  return img_result


gr.Interface(fn=inference, inputs=gr.inputs.Image(type="file"), 
             outputs=gr.outputs.Image()).launch(share=True) #debug=True Use in Colab

"""# **Part 2: Using Detectron2**

## **Install Detectron2**
"""

# install dependencies: 
!pip install pyyaml==5.1
# workaround: install old version of pytorch since detectron2 hasn't released packages for pytorch 1.9 (issue: https://github.com/facebookresearch/detectron2/issues/3158)
!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html

# install detectron2 that matches pytorch 1.8
# See https://detectron2.readthedocs.io/tutorials/install.html for instructions
!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html
# exit(0)  # After installation, you need to "restart runtime" in Colab. This line can also restart runtime

# check pytorch installation: 
import torch, torchvision
print(torch.__version__, torch.cuda.is_available())
assert torch.__version__.startswith("1.8")   # please manually install torch 1.8 if Colab changes its default version

"""## **Import libraries**"""

# Some basic setup:
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import os, json, cv2, random
from google.colab.patches import cv2_imshow

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog

"""## **Install dataset**"""

# Commented out IPython magic to ensure Python compatibility.
# Download Custom Dataset
# %mkdir /content/my_dataset/
# %cd /content/my_dataset
!curl -L "https://public.roboflow.com/ds/02YRTPxgQl?key=rpdH8yiWgF" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip

"""## **Instance Detction**"""

from detectron2.data.datasets import register_coco_instances
register_coco_instances("my_dataset_train", {}, "/content/my_dataset/train/json_annotation_train.json","/content/my_dataset/train")
register_coco_instances("my_dataset_valid", {}, "/content/my_dataset/valid/json_annotation_valid.json", "/content/my_dataset/valid")
register_coco_instances("my_dataset_test", {}, "/content/my_dataset/test/json_annotation_test.json", "/content/my_dataset/test")

# visualize training data
my_dataset_train_metadata = MetadataCatalog.get("my_dataset_train")
dataset_dicts = DatasetCatalog.get("my_dataset_train")

import random
from detectron2.utils.visualizer import Visualizer

for d in random.sample(dataset_dicts, 5):
    img = cv2.imread(d["file_name"])
    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)
    out = visualizer.draw_dataset_dict(d)
    cv2_imshow(out.get_image()[:, :, ::-1])
    print("\n")

# Train the model
from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
import os

# faster_rcnn
model_link = "COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml"

# Detectron2.config package
# https://detectron2.readthedocs.io/modules/config.html

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file(model_link))
cfg.DATASETS.TRAIN = ("my_dataset_train",)
cfg.DATASETS.TEST = ()
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_link) 
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025 
cfg.SOLVER.MAX_ITER = 1500 
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()

# Commented out IPython magic to ensure Python compatibility.
# Look at training curves in tensorboard:
# %load_ext tensorboard
# %tensorboard --logdir output

# Commented out IPython magic to ensure Python compatibility.
# Save model_final.pth 
# %cp /content/my_dataset/output/model_final.pth  /content/gdrive/MyDrive
print("Done ... ")

# Test evaluation
from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader
from detectron2.evaluation import COCOEvaluator, inference_on_dataset

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.50
predictor = DefaultPredictor(cfg)
evaluator = COCOEvaluator("my_dataset_valid", cfg, False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "my_dataset_valid")
inference_on_dataset(trainer.model, val_loader, evaluator)

# Inference & evaluation using the trained model
# cfg already contains everything we've set previously. Now we changed it a little bit for inference:
cfg = get_cfg()
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.DATASETS.TEST = ("my_dataset_test", )
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6   # set the testing threshold for this model
predictor = DefaultPredictor(cfg)
test_metadata = MetadataCatalog.get("my_dataset_test")

from detectron2.utils.visualizer import ColorMode
import glob

for imageName in glob.glob("/content/my_dataset/test/*jpg"):
  im = cv2.imread(imageName)
  outputs = predictor(im)
  v = Visualizer(im[:, :, ::-1],
                metadata=test_metadata, 
                scale=0.8
                 )
  out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
  cv2_imshow(out.get_image()[:, :, ::-1])
  print("\n")

"""## **Using Saved Model**"""

# Some basic setup:
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import os, json, cv2, random
from google.colab.patches import cv2_imshow

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog

# Mounting Google Drive
from google.colab import drive
drive.mount("/content/drive")

# Using saved model
my_cfg = get_cfg()
model_link = "COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml"
my_cfg.merge_from_file(model_zoo.get_config_file(model_link))
my_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # Set threshold for this model
my_cfg.MODEL.WEIGHTS = "/content/my_dataset/output/model_final.pth"
my_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
my_cfg.DATASETS.TEST = ("my_dataset_test", )
my_model_detectron2 = DefaultPredictor(my_cfg)
test_metadata = MetadataCatalog.get("my_dataset_test")

from detectron2.utils.visualizer import ColorMode
import glob

for imageName in glob.glob("/content/my_dataset/test/*.jpg"):
  im = cv2.imread(imageName)
  outputs = my_model_detectron2(im)
  print("Classes : \n", outputs["instances"].pred_classes)
  print("Scores : \n", outputs["instances"].scores)

  v = Visualizer(im[:, :, ::-1],
                metadata=test_metadata, 
                scale=0.8
                 )
  out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
  cv2_imshow(out.get_image()[:, :, ::-1])
  print("\n")

"""## **Inference** """

!pip install gradio

# https://www.gradio.app/ml_examples

# Using saved model
my_cfg = get_cfg()
model_link = "COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml"
my_cfg.merge_from_file(model_zoo.get_config_file(model_link))
my_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # Set threshold for this model
my_cfg.MODEL.WEIGHTS = "/content/gdrive/MyDrive/model_final.pth"
my_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
my_model_detectron2 = DefaultPredictor(my_cfg)

from detectron2.utils.visualizer import ColorMode

import numpy as np
import gradio as gr
import requests
#from PIL import Image
import cv2

def inference(img):
    H,W = 416, 416
    img = cv2.resize(img, (H, W)) 
    outputs = my_model_detectron2(img)
    v = Visualizer(img[:, :, ::-1],
                   metadata=test_metadata, 
                   scale=0.8
                 )
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    return out.get_image()[:, :, ::-1]

gr.Interface(fn=inference, 
             inputs=gr.inputs.Image(), 
             outputs=gr.outputs.Image()).launch(share=True) #debug=True Use in Colab